WEBVTT

00:00.080 --> 00:01.010
Hey, welcome.

00:01.010 --> 00:05.180
And in this video we're going to have a look at again how we can use the chat functionality inside of

00:05.180 --> 00:05.720
cursor.

00:05.720 --> 00:08.690
We're going to look at how you can integrate images into your workflow.

00:08.720 --> 00:13.850
This can be great if you're sketching a diagram, and you want to specifically figure out how you can

00:13.850 --> 00:17.450
integrate these diagrams into your code base driven development workflows.

00:17.450 --> 00:18.740
We've got a couple of notebooks.

00:18.740 --> 00:23.420
We're going to have a look at the story chain incomplete, and we have an idea of something that we

00:23.420 --> 00:24.080
want to generate.

00:24.080 --> 00:28.220
We have our several components of a story character generation chain.

00:28.220 --> 00:29.480
You have the story premise.

00:29.480 --> 00:30.890
Then we generate some characters.

00:30.890 --> 00:35.420
Then with the characters, we select a plot line and we do the plot line generation.

00:35.420 --> 00:40.040
Then with the plot outline, we then generate the scenes, which then go as a list of scenes.

00:40.040 --> 00:44.420
Each scene then generates some details of that scene, which then compiles the story.

00:44.420 --> 00:49.430
In the previous lesson, we looked at how we could index custom documentation from Lang Chain, so we're

00:49.430 --> 00:55.310
going to use that custom documentation plus the image to help us produce this LLM based story generation

00:55.310 --> 00:55.550
chain.

00:55.580 --> 00:59.000
The chain is basically just a series of inputs and outputs that build upon each other.

00:59.000 --> 01:00.350
Let's have a look at how we can do this.

01:00.380 --> 01:02.840
Firstly, inside the Jupyter notebook I'm going to hit command L.

01:02.840 --> 01:10.430
And then what I'm going to do is I'm going to say you are responsible for generating a story chain using

01:10.430 --> 01:13.250
line chain expression language.

01:13.280 --> 01:16.430
Now the next thing I need to do is I need to find that diagram.

01:16.430 --> 01:18.560
So I found that diagram locally.

01:18.800 --> 01:23.420
And you'll need to use a model that supports image recognition.

01:23.420 --> 01:25.730
So I'm going to use GPT four O mini.

01:25.730 --> 01:27.980
And then I'm going to go and get that diagram.

01:27.980 --> 01:31.160
I'm going to drag it into the chat just like this.

01:31.160 --> 01:33.950
And you'll now see there's an image over here.

01:33.950 --> 01:37.100
And I can either collapse it or I can look at what that image is.

01:37.100 --> 01:38.510
You could also remove it here.

01:38.510 --> 01:41.420
And then what we're going to do is we're going to then run it.

01:41.420 --> 01:46.220
And the reason why we've done that is because then we've given the entire Jupyter notebook, and we've

01:46.220 --> 01:50.390
got a visual representation of what we want the LLM to do.

01:50.390 --> 01:54.440
And now what we've got here is characters, the plots, the outlines.

01:54.440 --> 01:56.660
And so we can carry that across.

01:56.660 --> 01:59.690
So we'll say let's carry this across.

01:59.720 --> 02:01.160
So we're going to load a notebook here.

02:01.160 --> 02:06.080
And then we've got a runnable sequence and we're getting an error which is absolutely fine.

02:06.080 --> 02:10.310
So we're going to take that error and we're going to put this in there back into the chat.

02:10.370 --> 02:17.720
We're also going to say I want to make each step actually use a large language model.

02:17.930 --> 02:21.710
Also use LTL expression language.

02:21.770 --> 02:24.170
So we're still using that custom documentation.

02:24.170 --> 02:27.710
It's got the rough idea that we want some sort of sequence of steps.

02:27.710 --> 02:29.690
And we were also resolving a type error.

02:29.690 --> 02:31.790
For now it's just compiling these.

02:31.790 --> 02:33.710
And it's made them all in runnable lambdas.

02:33.710 --> 02:35.660
And then it's running it in a sequence.

02:35.660 --> 02:37.490
So let's have a look at that.

02:37.490 --> 02:41.330
Now I've got a different error which is expected runnable.

02:41.360 --> 02:44.030
But we got instead a class or a list.

02:44.060 --> 02:45.860
Let's see if we can fix this.

02:46.490 --> 02:49.640
So again I could read the documentation I could fix this.

02:49.640 --> 02:54.500
But basically what we're relying on is the fact that we can basically just use the custom documentation

02:54.500 --> 02:58.820
inside of cursor to immediately fix what's happening inside of the code.

02:58.820 --> 03:01.270
So in this scenario, it hasn't managed to fix it.

03:01.270 --> 03:09.070
So let's actually figure out why I want you to fix my code entirely and actually use.

03:09.070 --> 03:10.120
So let's have a look at that.

03:10.120 --> 03:14.860
So now it's decided it's actually going to create chat prompt templates, which looks a lot more like

03:14.860 --> 03:15.730
what we want to do.

03:15.760 --> 03:17.710
We have a bunch of runnable lambdas.

03:17.710 --> 03:19.330
We're formatting the prompts.

03:19.330 --> 03:21.880
And then let's go and copy this code and have a look.

03:21.880 --> 03:23.500
So we have these ones here.

03:23.500 --> 03:29.650
And now we're still getting a expected runnable callable or dict instead got an unsupported type of

03:29.650 --> 03:30.460
list.

03:30.460 --> 03:34.480
So these sequences should not be inside of a list.

03:34.480 --> 03:37.480
I think that this was the bit that was actually causing the error.

03:37.480 --> 03:43.150
And now what we have is a bunch of characters going into plots, and the plot outline goes into the

03:43.150 --> 03:47.200
scene, detail runnable, and then the story runnable will then run last.

03:47.200 --> 03:48.670
So we've got these prompt templates.

03:48.670 --> 03:52.960
We're currently using GPT four O mini, which is quite a good model and it's cost effective.

03:52.960 --> 03:55.960
And then you can see we have a range of different system prompts.

03:55.960 --> 04:01.450
We can see this is the story that it came back with, which is really nice with the call to adventure.

04:01.450 --> 04:05.470
We've got the trials and tribulations, and we've got the dark night of the soul, the climax and the

04:05.470 --> 04:06.070
resolution.

04:06.070 --> 04:08.800
Let's review some of the key learnings from this video.

04:08.830 --> 04:15.700
Images can provide rich context to cursor, so you can add an image, such as an architectural diagram,

04:15.700 --> 04:18.370
which can easily explain what the code needs to do.

04:18.400 --> 04:24.280
Also, another thing to note is that custom documentation retrieval or document retrieval steps don't

04:24.280 --> 04:28.990
always work, and you need to supplement this with either reading the documentation or understanding

04:28.990 --> 04:30.220
how the library works.

04:30.220 --> 04:35.920
Also, you should only use custom documentation if the framework or package or language is newer and

04:35.920 --> 04:37.960
is changing and is less stable.

04:37.960 --> 04:43.810
If you have a more stable package or framework or programming language such as Django, Laravel, flask

04:43.810 --> 04:49.300
or Express.js, then I recommend that you avoid using custom documentation, as this increases the latency

04:49.300 --> 04:53.080
and the time that it takes to get the request back from large language models.

04:53.080 --> 04:58.420
In the next video, we'll have a look at how you can use an image to easily mock out a UI in another

04:58.420 --> 05:00.070
tool called V0.
